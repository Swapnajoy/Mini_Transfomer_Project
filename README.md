# Mini_Transfomer_Project
Study different model architectures for processing sequential data and compare their results. The models are coded from scratch using PyTorch.

Document the observations during:

  training for loss curves, overfitting, plateauing etc. Experiment with the hyperparameters.
  
  inference, how the generated text compares with the other models. Generalization capability.
  
Visualize the results

Finally build a mini transformer based language model.

In Progress
